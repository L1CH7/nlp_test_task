data:
  raw_path: "data/ecg_data_raw.csv"
  clean_path: "data/ecg_data_clean.csv" 
  features:
    - rr_interval
    - p_onset
    - p_end
    - qrs_onset
    - qrs_end
    - t_end
    - p_axis
    - qrs_axis
    - t_axis
  label: "Healthy"
  split:
    test_size: 0.15
    dev_size: 0.15
    random_state: 42

prompts:
  simple: "promts/1.dat"
  detailed: "promts/2.dat"
  chain_of_thought: "promts/3.dat"
  medical_english: "promts/4.dat"

models:
  sklearn_methods:
    # Базовые методы с дефолтными параметрами
    - name: "LogisticRegression_Default"
      type: "sklearn"
      module: "sklearn.linear_model"
      class: "LogisticRegression"
      params:
        random_state: 42

    - name: "KNN_Default"
      type: "sklearn"
      module: "sklearn.neighbors"
      class: "KNeighborsClassifier"
      params:
        n_neighbors: 5

    - name: "RandomForest_Default" 
      type: "sklearn"
      module: "sklearn.ensemble"
      class: "RandomForestClassifier"
      params:
        random_state: 42

    - name: "XGBoost_Default"
      type: "sklearn"
      module: "xgboost"
      class: "XGBClassifier"
      params:
        random_state: 42
        use_label_encoder: false
        eval_metric: "logloss"

    # Оптимизированные методы для дисбаланса классов
    - name: "LogisticRegression_Balanced"
      type: "sklearn"
      module: "sklearn.linear_model"
      class: "LogisticRegression"
      params:
        C: 1.0
        max_iter: 1000
        class_weight: "balanced"
        random_state: 42

    - name: "RandomForest_Tuned"
      type: "sklearn"
      module: "sklearn.ensemble"
      class: "RandomForestClassifier"
      params:
        n_estimators: 300
        max_depth: 15
        min_samples_split: 5
        class_weight: "balanced"
        random_state: 42

    - name: "XGBoost_Tuned"
      type: "sklearn"
      module: "xgboost"
      class: "XGBClassifier"
      params:
        n_estimators: 300
        learning_rate: 0.05
        max_depth: 8
        scale_pos_weight: 2.7
        use_label_encoder: false
        eval_metric: "logloss"

  llm_methods:
    # Chat методы с разными промптами
    - name: "RuBERT_Chat_Simple"
      type: "llm_chat"
      model_name: "DeepPavlov/rubert-base-cased"
      prompt_key: "simple"
      device: 0

    - name: "RuBERT_Chat_Detailed"
      type: "llm_chat"
      model_name: "DeepPavlov/rubert-base-cased"
      prompt_key: "detailed"
      device: 0

    # Fine-tuned модели с разными параметрами обучения
    - name: "RuBERT_FineTuned_Fast"
      type: "llm_finetune"
      model_name: "DeepPavlov/rubert-base-cased"
      prompt_key: "simple"
      device: 0
      save_model: true
      save_path: "models/rubert_fast"
      training_params:
        num_train_epochs: 10
        per_device_train_batch_size: 16
        learning_rate: 3e-5
        weight_decay: 0.01
        warmup_steps: 50

    - name: "RuBERT_FineTuned_Careful"
      type: "llm_finetune"
      model_name: "DeepPavlov/rubert-base-cased"
      prompt_key: "simple"
      device: 0
      save_model: true
      save_path: "models/rubert_careful"
      training_params:
        num_train_epochs: 20
        per_device_train_batch_size: 8
        learning_rate: 1e-5
        weight_decay: 0.05
        warmup_steps: 100
        lr_scheduler_type: "cosine"

    - name: "RuBERT_FineTuned_Aggressive"
      type: "llm_finetune"
      model_name: "DeepPavlov/rubert-base-cased"
      prompt_key: "simple"
      device: 0
      save_model: true
      save_path: "models/rubert_aggressive"
      training_params:
        num_train_epochs: 50
        per_device_train_batch_size: 4
        learning_rate: 5e-6
        weight_decay: 0.1
        warmup_ratio: 0.1
        lr_scheduler_type: "linear"

    # Медицинские модели
    - name: "BiomedBERT_FineTuned"
      type: "llm_finetune"
      model_name: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"
      prompt_key: "medical_english"
      device: 0
      save_model: true
      save_path: "models/biomedbert"
      training_params:
        num_train_epochs: 15
        per_device_train_batch_size: 8
        learning_rate: 2e-5
        weight_decay: 0.02

    - name: "ClinicalBERT_FineTuned"
      type: "llm_finetune"
      model_name: "emilyalsentzer/Bio_ClinicalBERT"
      prompt_key: "medical_english"
      device: 0
      save_model: true
      save_path: "models/clinicalbert"
      training_params:
        num_train_epochs: 15
        per_device_train_batch_size: 8
        learning_rate: 2e-5
        weight_decay: 0.02

    # Базовые методы
    - name: "Rule_Based"
      type: "rule_based"

experiments:
  results_csv: "results.csv"
  shuffle_data: true
  stratify: true
  model_cache_dir: "models/"
